from pyspark.sql.functions import udf, col, regexp_replace, rank
from pyspark.sql.types import DoubleType
from pyspark.sql.window import Window

df = spark.read.option("header", "true").csv("/FileStore/tables/startups.csv")

def convert_currency(value):
    if value is None:
        return None
    value = value.replace("$", "").strip()
    try:
        if value.endswith("B"):
            return float(value[:-1]) * 1_000_000_000
        elif value.endswith("M"):
            return float(value[:-1]) * 1_000_000
        else:
            return float(value.replace(",", ""))
    except:
        return None

currency_udf = udf(convert_currency, DoubleType())

df_clean = df.withColumn("ARR_Num", currency_udf("ARR")) \
             .withColumn("Valuation_Num", currency_udf("Valuation")) \
             .withColumn("Funding_Num", currency_udf("Total Funding"))

df_clean.createOrReplaceTempView("startups_clean")
df_clean.select("Company Name", "ARR", "ARR_Num", "Valuation", "Valuation_Num", "Total Funding", "Funding_Num").show(5)



window_spec = Window.partitionBy("Industry").orderBy(col("Valuation_Num").desc())

ranked_df = df_clean.withColumn("rank", rank().over(window_spec)) \
                    .filter(col("rank") <= 2) \
                    .select("Industry", "Company Name", "Valuation", "Valuation_Num", "rank") \
                    .orderBy("Industry", "rank")

ranked_df.show(50, truncate=False)
